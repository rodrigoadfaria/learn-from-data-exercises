\begin{enunciado}{23}
   Consider the learning problem  n Example 2.8, where the input space is $\xset = [-1, + 1]$ , the target function is $f(x) = sin(\pi x)$ , and the input probability distribution is uniform on $\mathscr{X}$. Assume that the training set $\dset$ has only two data points (picked independently), and that the learning algorithm picks the hypothesis that minimizes the in sample mean squared error. In this problem, we will dig deeper into this case.
   
For each of the following learning models, find (analytically or numerically)
(i) the best hypothesis that approximates $f$ in the mean squared error sense
(assume that $f$ is known for this part), (ii) the expected value (with respect
to $\dset$) of the hypothesis that the learning algorithm produces, and (iii) the expected out of sample error and its bias and var components.

\letra{a} The learning model consists of all hypotheses of the form $h(x) = ax + b$
(if you need to deal with the infinitesimal probability case of two identical data points, choose the hypothesis tangential to $f$).

\letra{b} The learning model consists of all hypotheses of the form $h(x) = ax$. This case was not covered in Example 2.8.

\letra{c} The learning model consists of all hypotheses of the form $h(x) = b$.
   
\end{enunciado}

Resposta resposta resposta